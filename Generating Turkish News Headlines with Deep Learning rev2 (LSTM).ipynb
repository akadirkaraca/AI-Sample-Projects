{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Drcc9OocSKFX",
        "tmeVu9E93y11",
        "Au7New1G38qR"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMHugFnZbGJL"
      },
      "source": [
        "# **Thesis v2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehcXYp_cCgOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ba6d64-cd5d-4d2d-e036-a9f730337ac2"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding, CuDNNGRU, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.python.training import training\n",
        "from tensorflow.python.client import device_lib\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow==2.4.1\n",
        "# !pip install keras==2.3.1"
      ],
      "metadata": {
        "id": "AMqZOPc-jeVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fr3q1sXUSOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c628d4c8-da98-45e2-a1a7-73ac47ba1c3f"
      },
      "source": [
        "try:\n",
        "  drive.mount('/content/drive')\n",
        "  os.chdir(\"drive/My Drive/GoogleColab/\")\n",
        "  print('Dosya dizini belirtilen konuma ayarlandı.')\n",
        "except:\n",
        "  print('Dosya dizini belirtilen konumda...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dosya dizini belirtilen konuma ayarlandı.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "Q2NJq_XXGbla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e166740b-7e46-4a3a-a0cc-cb098aa0a645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "2Z0T9ECuGeVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecfa7242-4063-404c-f426-3db89cf10e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 37.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Uth8v6cuc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3eae7f-5fb1-4958-bf84-036a19ba92ba"
      },
      "source": [
        "try:\n",
        "  %load_ext tensorboard\n",
        "  print(\"TensorBoard eklentisi kuruldu.\")\n",
        "finally:\n",
        "  %rm -rf ./logs/\n",
        "  print(\"Önceki çalıştırmalardan elde edilen günlükler temizlendi.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorBoard eklentisi kuruldu.\n",
            "Önceki çalıştırmalardan elde edilen günlükler temizlendi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0C7QUAQCqVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126c6ff9-3eb2-4772-8d00-ad9f4fca1aed"
      },
      "source": [
        "if tf.executing_eagerly():\n",
        "  print(\"İstekli çalışma modu çalışıyor.\")\n",
        "else:\n",
        "  tf.compat.v1.enable_eager_execution()\n",
        "  print(\"İstekli çalışma moduna geçildi.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "İstekli çalışma modu çalışıyor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGcKfdQdX5wB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4835b822-fa86-45d3-d80b-d31eea85ad7f"
      },
      "source": [
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.4.1\n",
            "Eager execution: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I60tW0vL3vW"
      },
      "source": [
        "### **Verileri Yükleme**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document = pd.read_csv('preparedSuDerDataset.csv')\n",
        "document.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "\n",
        "news_texts = document['News']\n",
        "title_texts = document['Title']\n",
        "\n",
        "series_news_texts = pd.Series(news_texts)\n",
        "series_title_texts = pd.Series(title_texts)"
      ],
      "metadata": {
        "id": "OzCs9JQh8vZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idM7UhL5urDb"
      },
      "source": [
        "**Dataset Train ve Validation Olarak Bölme**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_train, news_validation, title_train, title_validation = train_test_split(series_news_texts, series_title_texts, test_size=0.1)"
      ],
      "metadata": {
        "id": "iopOA3xluymU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMrgkfaYMzaw"
      },
      "source": [
        "**Metinleri tokenlere(jeton, vektör) Dönüştürme**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N35KRXEXtUOl"
      },
      "source": [
        "# '<' ve '>' varsayılan belirteçlerden kaldırılamaz. Çünkü dekoder için hedef derlemimizi bu işaretler arasına aldık\n",
        "# Gerekli olan filtreleme işlemini news_preprocess ve title_preprocess fonksionlarıyla yaptık\n",
        "filters = '!\"$%()*+,./:;=?@[\\\\]^_{|}~\\t\\n'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdXhzNaHsny9"
      },
      "source": [
        "#news_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters)\n",
        "#title_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters)\n",
        "news_tokenizer = keras.preprocessing.text.Tokenizer(filters=filters, oov_token='<unk>', num_words=2)\n",
        "title_tokenizer = keras.preprocessing.text.Tokenizer(filters=filters, oov_token='<unk>', num_words=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzgHX8fCll37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ffada4-1956-41b2-e28a-a5fa4af1f24f"
      },
      "source": [
        "print(\"Haber metinlerinin vektör sözlüğü oluşturuluyor...\")\n",
        "news_tokenizer.fit_on_texts(news_train)\n",
        "print(\"Haber metinlerinin vektör sözlüğü oluşturuldu.\")\n",
        "\n",
        "print(\"Haber başlıklarının vektör sözlüğü oluşturuluyor...\")\n",
        "news_tokenizer.fit_on_texts(title_train)\n",
        "# title_tokenizer.fit_on_texts(title_train)\n",
        "print(\"Haber başlıklarının vektör sözlüğü oluşturuldu.\")\n",
        "# --------------------------------------------------------------------\n",
        "# print(\"Haber metinlerinin vektör sözlüğü oluşturuluyor...\")\n",
        "# news_tokenizer.fit_on_texts(series_news_texts)\n",
        "# print(\"Haber metinlerinin vektör sözlüğü oluşturuldu.\")\n",
        "\n",
        "# print(\"Haber başlıklarının vektör sözlüğü oluşturuluyor...\")\n",
        "# news_tokenizer.fit_on_texts(series_title_texts)\n",
        "# print(\"Haber başlıklarının vektör sözlüğü oluşturuldu.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Haber metinlerinin vektör sözlüğü oluşturuluyor...\n",
            "Haber metinlerinin vektör sözlüğü oluşturuldu.\n",
            "Haber başlıklarının vektör sözlüğü oluşturuluyor...\n",
            "Haber başlıklarının vektör sözlüğü oluşturuldu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZf2sju4wdvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf66f862-d3fc-4625-e467-9d39c6e9f93e"
      },
      "source": [
        "print(\"Haber metinleri vektörleştiriliyor...\")\n",
        "inputs = news_tokenizer.texts_to_sequences(news_train)\n",
        "print(\"Haber metinleri vektörleştirildi.\")\n",
        "\n",
        "print(\"Haber başlıkları vektörleştiriliyor...\")\n",
        "# targets = title_tokenizer.texts_to_sequences(title_train)\n",
        "targets = news_tokenizer.texts_to_sequences(title_train)\n",
        "print(\"Haber başlıkları vektörleştirildi.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Haber metinleri vektörleştiriliyor...\n",
            "Haber metinleri vektörleştirildi.\n",
            "Haber başlıkları vektörleştiriliyor...\n",
            "Haber başlıkları vektörleştirildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBG1ciE0mP4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa86fb0-02c4-43e5-a1af-4189e214e20a"
      },
      "source": [
        "encoder_vocab_size = len(news_tokenizer.word_index) + 1 \n",
        "decoder_vocab_size = len(news_tokenizer.word_index) + 1\n",
        "# decoder_vocab_size = len(title_tokenizer.word_index) + 1\n",
        "\n",
        "print('Encoder sözlük sayısı: {}\\nDecoder sözlük sayısı: {}'.format(encoder_vocab_size, decoder_vocab_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder sözlük sayısı: 806744\n",
            "Decoder sözlük sayısı: 806744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTObH43jR_iT"
      },
      "source": [
        "**Haber ve başlık metinlerinin ayrı ayrı uzunluklarını tanımlama**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWt_tqmjmWdN"
      },
      "source": [
        "# news_train_lengths = pd.Series([len(x.split()) for x in news_train])\n",
        "# title_train_lengths = pd.Series([len(x.split()) for x in title_train])\n",
        "\n",
        "# news_validation_lengths = pd.Series([len(x.split()) for x in news_validation])\n",
        "# title_validation_lengths = pd.Series([len(x.split()) for x in title_validation])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nITLk20QPKCx"
      },
      "source": [
        "encoder_maxlen = 352\n",
        "decoder_maxlen = 12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSSytB5ZxbC2"
      },
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    inputs,\n",
        "    maxlen=encoder_maxlen,\n",
        "    padding='post',\n",
        "    truncating='post')\n",
        "\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    targets,\n",
        "    maxlen=decoder_maxlen,\n",
        "    padding='post',\n",
        "    truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyEgdN4txbOa"
      },
      "source": [
        "# tf.cast almış olduğu x vektör dizisini (bu kod bloğunda inputs ve targets) tensör olarak döndürür. Tensörler numpy() dizileri gibi düşünülebilir\n",
        "encoder_input_data = inputs\n",
        "decoder_input_data = targets[:, :-1]\n",
        "decoder_output_data = targets[:, 1:]\n",
        "\n",
        "inputs = tf.cast(encoder_input_data, dtype=tf.int32)\n",
        "decoder_input_data = tf.cast(decoder_input_data, dtype=tf.int32)\n",
        "decoder_output_data = tf.cast(decoder_output_data, dtype=tf.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNQfaEClxbZB"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EMBEDDING_SIZE = 256 # Sözlük boyutu (dimension)\n",
        "STATE_SIZE = 256 # Katmanlar arası nöron sayısı"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder_embedding = Embedding(input_dim = encoder_vocab_size, output_dim = EMBEDDING_SIZE, name = 'encoder_embedding')"
      ],
      "metadata": {
        "id": "RE4MDH8HWBwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder_gru1 = LSTM(STATE_SIZE, name='encoder_gru1', return_sequences = True)\n",
        "# encoder_gru2 = LSTM(STATE_SIZE, name='encoder_gru2', return_sequences = True)\n",
        "# encoder_gru3 = LSTM(STATE_SIZE, name='encoder_gru3', return_sequences = False)"
      ],
      "metadata": {
        "id": "-2qWe61mWTYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder_input = Input(shape=(None,), name='encoder_input')"
      ],
      "metadata": {
        "id": "nwG1jH9qWVYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def connect_encoder():\n",
        "#     net = encoder_input\n",
        "#     net = encoder_embedding(net)\n",
        "    \n",
        "#     net = encoder_gru1(net)\n",
        "#     net = encoder_gru2(net)\n",
        "#     net = encoder_gru3(net)\n",
        "    \n",
        "#     encoder_output = net\n",
        "    \n",
        "#     return encoder_output"
      ],
      "metadata": {
        "id": "wpIb5TNaWrOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "# encoder_inputs = Input(shape=(encoder_maxlen, ))\n",
        "encoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# Embedding layer\n",
        "encoder_embedding = Embedding(encoder_vocab_size, EMBEDDING_SIZE, name=\"EncoderEmbedding\") # arg* ---> trainable=True\n",
        " \n",
        "# Encoder LSTM 1\n",
        "encoder_lstm1 = LSTM(STATE_SIZE, return_sequences=True,return_state=True, dropout=0.4,recurrent_dropout=0.4, name='EncoderLSTM-1')\n",
        "# Encoder LSTM 2\n",
        "encoder_lstm2 = LSTM(STATE_SIZE, return_sequences=True,return_state=True, dropout=0.4,recurrent_dropout=0.4, name=\"EncoderLSTM-2\")\n",
        "# Encoder LSTM 3\n",
        "encoder_lstm3 = LSTM(STATE_SIZE, return_state=True, return_sequences=True, dropout=0.4,recurrent_dropout=0.4, name=\"EncoderLSTM-3\")\n",
        "\n",
        "def connect_encoder():\n",
        "\n",
        "    net = encoder_embedding(encoder_inputs)\n",
        "    \n",
        "    (encoder_outputs1, state_h1, state_c1) = encoder_lstm1(net)\n",
        "    (encoder_outputs2, state_h2, state_c2) = encoder_lstm2(encoder_outputs1)\n",
        "    (encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_outputs2)\n",
        "\n",
        "    return encoder_outputs, state_h, state_c"
      ],
      "metadata": {
        "id": "QMsI8qOlFK8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_outputs, state_h, state_c = connect_encoder()\n",
        "initial_state = [state_h, state_c]"
      ],
      "metadata": {
        "id": "QDadU4FjW7bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_initial_state = Input(shape=(STATE_SIZE,), name='decoder_initial_size')"
      ],
      "metadata": {
        "id": "0Z0HkvKbXC3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_input = Input(shape=(None, ), name='decoder_input')"
      ],
      "metadata": {
        "id": "sYxB9Nv4XIH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_embedding = Embedding(input_dim = encoder_vocab_size, output_dim = EMBEDDING_SIZE, name = 'encoder_embedding')"
      ],
      "metadata": {
        "id": "5fAJSDrUXMHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_gru1 = LSTM(STATE_SIZE, name='decoder_gru1', return_sequences=True)\n",
        "# decoder_gru2 = LSTM(STATE_SIZE, name='decoder_gru2', return_sequences=True)\n",
        "# decoder_gru3 = LSTM(STATE_SIZE, name='decoder_gru3', return_sequences=True)"
      ],
      "metadata": {
        "id": "rOzz8iDRaapS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_dense = Dense(decoder_vocab_size, activation='linear', name='decoder_output')"
      ],
      "metadata": {
        "id": "wCP0Gx11ahiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def connect_decoder(initial_state):\n",
        "#     net = decoder_input\n",
        "\n",
        "#     net = decoder_embedding(net)\n",
        "\n",
        "#     net, hidden_h = decoder_gru1(net, initial_state = initial_state)\n",
        "#     net, hidden_h,hidden_c = decoder_gru2(net, initial_state = initial_state)\n",
        "#     net, hidden_h,hidden_c = decoder_gru3(net, initial_state = initial_state)\n",
        "\n",
        "#     # net = decoder_gru1(net, initial_state=initial_state)\n",
        "#     # net = decoder_gru2(net, initial_state=initial_state)\n",
        "#     # net = decoder_gru3(net, initial_state=initial_state)\n",
        "    \n",
        "#     decoder_output, hidden_h,hidden_c = decoder_dense(net)\n",
        "    \n",
        "#     return decoder_output"
      ],
      "metadata": {
        "id": "Br_w56bLajUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def connect_decoder(initial_state):\n",
        "\n",
        "#     net = decoder_input\n",
        "#     net = decoder_embedding(net)\n",
        "    \n",
        "#     (decoder_outputs1, decoder_fwd_state, decoder_back_state) = decoder_lstm1(dec_emb, initial_state=[state_h, state_c])\n",
        "#     net = decoder_gru1(net, initial_state=initial_state)\n",
        "#     net = decoder_gru2(net, initial_state=initial_state)\n",
        "#     net = decoder_gru3(net, initial_state=initial_state)\n",
        "    \n",
        "#     decoder_output = decoder_dense(net)\n",
        "    \n",
        "#     return decoder_output"
      ],
      "metadata": {
        "id": "qvw2ap5xU5an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# Embedding layer\n",
        "decoder_embedding = Embedding(decoder_vocab_size, EMBEDDING_SIZE, trainable=True, name=\"DecoderEmbedding\")\n",
        "\n",
        "# Decoder LSTM\n",
        "decoder_lstm1 = LSTM(STATE_SIZE, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2, name=\"DecoderLSTM-1\")\n",
        "# Decoder LSTM 2\n",
        "decoder_lstm2 = LSTM(STATE_SIZE, return_sequences=True,return_state=True, dropout=0.4,recurrent_dropout=0.4, name=\"DecoderLSTM-2\")\n",
        "# Decoder LSTM 3\n",
        "decoder_lstm3 = LSTM(STATE_SIZE, return_state=True,return_sequences=True, dropout=0.4,recurrent_dropout=0.4, name=\"DecoderLSTM-3\")\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(decoder_vocab_size, activation='softmax'), name=\"DecoderDense\")\n",
        "\n",
        "def connect_decoder(initial_state):\n",
        "\n",
        "    dec_emb = decoder_embedding(decoder_inputs)\n",
        "    \n",
        "    (decoder_outputs, decoder_fwd_state, decoder_back_state) = decoder_lstm1(dec_emb, initial_state=initial_state)\n",
        "    \n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    \n",
        "    return decoder_outputs"
      ],
      "metadata": {
        "id": "OR59-hxDAkgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_outputs = connect_decoder(initial_state)"
      ],
      "metadata": {
        "id": "5S2E5wkuaszE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_train = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)"
      ],
      "metadata": {
        "id": "8fEhVM6ha7MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_encoder = Model(inputs=[encoder_inputs], outputs=[encoder_outputs])"
      ],
      "metadata": {
        "id": "Z-JOPbhVuajx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_output = connect_decoder(initial_state=decoder_initial_state)\n",
        "model_decoder = Model(inputs=[decoder_inputs, encoder_inputs], outputs=[decoder_outputs])"
      ],
      "metadata": {
        "id": "Ca8asbgBucLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_cross_entropy(y_true, y_pred):\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
        "    loss_mean = tf.reduce_mean(loss)\n",
        "    return loss_mean"
      ],
      "metadata": {
        "id": "CsFFAL2PucpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "Rw2lMjnSucwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_train.compile(optimizer=optimizer, loss=sparse_cross_entropy, metrics=['accuracy'], run_eagerly=True)"
      ],
      "metadata": {
        "id": "toO5mFzZumM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint_path = \"/checkpoints/rev2/lstm/metrics/train/keras_embedding.ckpt-0.data-00000-of-00001\"\n",
        "# checkpoint = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True)"
      ],
      "metadata": {
        "id": "7FxhbvqQuve0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    model_train.load_weights(checkpoint_path)\n",
        "    print('Eğitim ağırlıkları yüklendi...\\n')\n",
        "except Exception as error:\n",
        "    print('Checkpoint yüklenirken hata oluştu. Eğitime başlanıyor...\\n')\n",
        "    print(error)"
      ],
      "metadata": {
        "id": "Ydxv97ykvElG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa89aa9a-16ab-481d-cc38-dfba1cd441cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint yüklenirken hata oluştu. Eğitime başlanıyor...\n",
            "\n",
            "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /checkpoints/rev2/lstm/metrics/train/keras_embedding.ckpt-0.data-00000-of-00001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "2i65xoZXab4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = {'encoder_input':encoder_input_data, 'decoder_input':decoder_input_data}\n",
        "y_data = {'decoder_output':decoder_output_data}"
      ],
      "metadata": {
        "id": "fm4Q3ktFylLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = tf.keras.callbacks.TensorBoard(log_dir='checkpoints/rev2/lstm/metrics', histogram_freq=1, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)"
      ],
      "metadata": {
        "id": "RiTjD8_wyyYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_train.summary()"
      ],
      "metadata": {
        "id": "sL1VkZZdy_J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_decoder.summary()"
      ],
      "metadata": {
        "id": "GxvfWRDFb96i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_encoder.summary()"
      ],
      "metadata": {
        "id": "MOsxpHyhfotI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_train.fit(x=[encoder_input_data, decoder_input_data], y=decoder_output_data, batch_size=64, epochs=25, callbacks=[callbacks], validation_split=0.2)"
      ],
      "metadata": {
        "id": "_LMrKBa9zKV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sequential**"
      ],
      "metadata": {
        "id": "Drcc9OocSKFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "latent_dim = STATE_SIZE # state size\n",
        "embedding_dim = EMBEDDING_SIZE\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(encoder_maxlen, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(encoder_vocab_size, embedding_dim, trainable=True)(encoder_inputs)\n",
        "\n",
        "# Encoder LSTM 1\n",
        "encoder_lstm1 = LSTM(latent_dim, return_sequences=True,return_state=True, dropout=0.4,recurrent_dropout=0.4)\n",
        "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
        "\n",
        "# Encoder LSTM 2\n",
        "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,return_state=True, dropout=0.4,recurrent_dropout=0.4)\n",
        "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# Encoder LSTM 3\n",
        "encoder_lstm3 = LSTM(latent_dim, return_state=True, return_sequences=False, dropout=0.4,recurrent_dropout=0.4)\n",
        "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# Embedding layer\n",
        "dec_emb_layer = Embedding(decoder_vocab_size, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# Decoder LSTM\n",
        "decoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
        "(decoder_outputs1, decoder_fwd_state, decoder_back_state) = decoder_lstm1(dec_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "# Decoder LSTM 2\n",
        "decoder_lstm2 = LSTM(latent_dim, return_sequences=True,return_state=True, dropout=0.4,recurrent_dropout=0.4)\n",
        "(decoder_output2, state_h3, state_c3) = decoder_lstm2(decoder_outputs1)\n",
        "\n",
        "# Decoder LSTM 3\n",
        "decoder_lstm3 = LSTM(latent_dim, return_state=True,return_sequences=True, dropout=0.4,recurrent_dropout=0.4)\n",
        "(decoder_outputs3, state_h4, state_c4) = decoder_lstm3(decoder_output2)\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(decoder_vocab_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs3)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Ct82w0MaywTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer, loss=sparse_cross_entropy, metrics=['accuracy'], run_eagerly=True)"
      ],
      "metadata": {
        "id": "nGIrf9XxFvtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"checkpoints/rev2/gru\"\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True)"
      ],
      "metadata": {
        "id": "LqdN_rPwF2zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    model_train.load_weights(path_checkpoint)\n",
        "except Exception as error:\n",
        "    print('Checkpoint yüklenirken hata oluştu. Eğitime başlanıyor...\\n')\n",
        "    print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW3-3-nnF2zv",
        "outputId": "26878acc-73a0-4f8b-95bc-d72d9f8e05b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint yüklenirken hata oluştu. Eğitime başlanıyor...\n",
            "\n",
            "name 'model_train' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = {'encoder_input':encoder_input_data, 'decoder_input':decoder_input_data}\n",
        "y_data = {'decoder_output':decoder_output_data}"
      ],
      "metadata": {
        "id": "lwWyFpgEF2zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = tf.keras.callbacks.TensorBoard(log_dir='checkpoints/rev2/gru/metrics', histogram_freq=1, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)"
      ],
      "metadata": {
        "id": "74y9CPDYF2zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit([encoder_input_data,decoder_input_data],decoder_output_data,epochs=50,callbacks=[callbacks],batch_size=8)"
      ],
      "metadata": {
        "id": "QsSbLYsWF2zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the model learning\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "gqbeLW2uZ_wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, let’s build the dictionary to convert the index to word for target and source vocabulary:\n",
        "reverse_target_word_index=title_tokenizer.index_word\n",
        "reverse_source_word_index=news_tokenizer.index_word\n",
        "target_word_index=title_tokenizer.word_index"
      ],
      "metadata": {
        "id": "y0R_pO-qZ_8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(STATE_SIZE,))\n",
        "decoder_state_input_c = Input(shape=(STATE_SIZE,))\n",
        "decoder_hidden_state_input = Input(shape=(encoder_maxlen,STATE_SIZE))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "metadata": {
        "id": "mvidavJ0aAge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We are defining a function below which is the implementation of the inference process\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "OECy189laabc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews:\n",
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "metadata": {
        "id": "zx_2cis5agUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the model over the data to see the results\n",
        "for i in range(0,100):\n",
        "    print(\"Review:\",seq2text(news_train[i]))\n",
        "    print(\"Original summary:\",seq2summary(title_train[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(news_train[i].reshape(1,maxlen)))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "Ma_P36HuaAtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tioQ1JplaA21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcPr0jGjP3kF"
      },
      "source": [
        "# **Compute Score**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmeVu9E93y11"
      },
      "source": [
        "### **BLEU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmulKgj6etYA"
      },
      "source": [
        "!pip install --upgrade bleu\n",
        "from bleu import list_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uRuPmwR32f7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U61vrCFUlQtW"
      },
      "source": [
        "ref = [\"\"\"thy nin yolcu sayısı ### milyona ulaştı\"\"\"]\n",
        "hyp = [\"\"\"THY yolcu sayısını 9.2 milyona çıkardı\"\"\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRcL8nizOHC6"
      },
      "source": [
        "list_bleu([ref], hyp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PzjJaYk4CWl"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TKNYPySlv_X"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VA0VvqMlGOk"
      },
      "source": [
        "hypothesis = \"### terörist etkisiz hale getirildi\".split()\n",
        "reference = title_preprocess(\"Bitlis'te 6 teröristin öldürüldüğü operasyonda çok sayıda silah mühimmat ele geçirildi\").split()\n",
        "#there may be several references\n",
        "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis,auto_reweigh=True)\n",
        "print(BLEUscore*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaI_pZ_dQas1"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u825Q0MAQ3nW"
      },
      "source": [
        "# two references for one document\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "references = [[\"\".split()]]\n",
        "candidates = [\"\".split(), \"\".split()]\n",
        "score = corpus_bleu(references, candidates)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au7New1G38qR"
      },
      "source": [
        "### **ROUGE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-yiF5xP9sq7"
      },
      "source": [
        "!pip install 0 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzcvzawjjEJH"
      },
      "source": [
        "from rouge_metric import PyRouge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZQ4057r97Ox"
      },
      "source": [
        "By default, sentences are separated by '\\n' and tokens are separated by white space in a document. This tokenization process can be further customized. For example,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwrwbETi99fn"
      },
      "source": [
        "# # Template\n",
        "# from rouge_metric import PyRouge\n",
        "\n",
        "# # Pre-process and tokenize the summaries as you like\n",
        "# hypotheses = [\n",
        "#     ['how are you'.split(), 'i am fine'.split()],                       # document 1: hypothesis\n",
        "#     ['it is fine today'.split(), 'we won the football game'.split()],   # document 2: hypothesis\n",
        "# ]\n",
        "# references = [[\n",
        "#     ['how do you do'.split(), 'fine thanks'.split()],   # document 1: reference 1\n",
        "#     ['how old are you'.split(), 'i am three'.split()],  # document 1: reference 2\n",
        "# ], [\n",
        "#     ['it is sunny today'.split(), 'let us go for a walk'.split()],  # document 2: reference 1\n",
        "#     ['it is a terrible day'.split(), 'we lost the game'.split()],   # document 2: reference 2\n",
        "# ]]\n",
        "\n",
        "# # Evaluate on tokenized documents\n",
        "# rouge = PyRouge(rouge_n=(1, 2, 4), rouge_l=True, rouge_w=True,\n",
        "#                 rouge_w_weight=1.2, rouge_s=True, rouge_su=True, skip_gap=4)\n",
        "# scores = rouge.evaluate_tokenized(hypotheses, references)\n",
        "# print(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgkWFSYBjrmm"
      },
      "source": [
        "# hypotheses = [\"kavga ### can alan maganda vurdu\".split()]\n",
        "# references = [\"Kavga sebebi sudan faturası ise iki can\".split()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz8QqATdkQ5s"
      },
      "source": [
        "# print(hypotheses)\n",
        "# print(references)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBMUse4rkXLk"
      },
      "source": [
        "# references = [title.split() for title in title_texts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNJaKiFYknfT"
      },
      "source": [
        "# hypotheses20 = [generate_title(news_preprocess(news)).split() for news in news_texts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O6m4e0_FIvI7"
      },
      "source": [
        "# hypotheses20 = news_texts.progress_apply(lambda x: generate_title(news_preprocess(str(x))) if i < range(25000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJwL6Kkc1Kgd"
      },
      "source": [
        "hypotheses25 = []\n",
        "references = []\n",
        "\n",
        "# tqdm.pandas(desc=\"Progress\")\n",
        "# for i in tqdm(range(25000,52489)):\n",
        "#   hypotheses20.append(generate_title(news_preprocess(news_texts[i])).split())\n",
        "#   references.append(title_texts[i].split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSQtV6eY4Vnc"
      },
      "source": [
        "dict_rouge = {\"Tahmin - 25 Epoch\":hypotheses25}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIKZjKttVQZ0"
      },
      "source": [
        "df = pd.DataFrame(dict_rouge)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mIljRtUVbpC"
      },
      "source": [
        "df.to_csv(\"s25k25e.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chsb1eB5VgkC"
      },
      "source": [
        "for i in tqdm(range(25000,52489)):\n",
        "  hypotheses25.append(generate_title(news_preprocess(news_texts[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Üretme**"
      ],
      "metadata": {
        "id": "1I50T26rZ5x5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlsXl7OC6lMU"
      },
      "source": [
        "# token_start = title_tokenizer.word_index[_START_.strip()]\n",
        "# token_end = title_tokenizer.word_index[_END_.strip()]\n",
        "_START_ = '<tstart>'\n",
        "_END_ = '<tend>'\n",
        "token_start = news_tokenizer.word_index[_START_.strip()]\n",
        "token_end = news_tokenizer.word_index[_END_.strip()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwPqsXWddKQf"
      },
      "source": [
        "def generate(input_text, true_output_text=None):\n",
        "\n",
        "  input_tokens = news_tokenizer.texts_to_sequences([input_text])\n",
        "  input_tokens = np.array(input_tokens)\n",
        "\n",
        "  initial_state = model_encoder.predict(input_tokens)\n",
        "\n",
        "  decoder_input_data = np.zeros(shape=(1,decoder_maxlen), dtype=np.int32)\n",
        "\n",
        "  token_int = _START_\n",
        "  output_text=' '\n",
        "  count_tokens=0\n",
        "\n",
        "  while token_int != token_end and count_tokens < decoder_maxlen:\n",
        "    decoder_input_data[0, count_tokens] = token_int\n",
        "    x_data = {'decoder_input':decoder_input_data, 'decoder_initial_size':initial_state}\n",
        "\n",
        "    decoder_output = model_decoder.predict(x_data)\n",
        "\n",
        "    token_onehot = decoder_output[0, count_tokens,:]\n",
        "    token_int = np.argmax(token_onehot)\n",
        "\n",
        "    sample_word = title_tokenizer.index_word[token_int]\n",
        "    output_text += ' '+sample_word\n",
        "    count_tokens+= 1\n",
        "\n",
        "  print('Girdi:')\n",
        "  print(input_text)\n",
        "  print()\n",
        "\n",
        "  print('Üretililen Başlık:')\n",
        "  print(output_text)\n",
        "  print()\n",
        "\n",
        "  print('Gerçek Başlık:')\n",
        "  print(true_output_text)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byldk3d3fyu-"
      },
      "source": [
        "index = 39546\n",
        "news_texts[index], title_texts[index]\n",
        "n = text_cleaner(news_texts[index])\n",
        "t = title_cleaner(title_texts[index])\n",
        "generate(n,true_output_text=t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUe7H_qDc1F_",
        "outputId": "5ea4ece0-0641-4a75-cd59-1e9fa3db2e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<istart> izmir deki asker tutuklu sanığın yargılandığı gizli bilgi belge bulundurma davasında asker tutuklu sanık tahliye edildi izmir ağır ceza mahkemesi nde görülen davaya tutuklu tutuksuz sanıkların avukatları katıldı mahkeme başkanı duruşma boyunca sürekli izin almadan konuştuğu gerekçesiyle davanın numaralı sanığı bilgin özkaynak salonundan çıkardı mahkeme heyeti tutuklu sanıklardan ercan yabuloğlu meryem erturan muvazzaf askerler atilla kaya bülent kul doğan şahin hasan kızılaslan hüseyin cengiz ibrahim aydın mustafa ufuk kök ihsan kürşat toksoy hakan gürdal burhan kahraman nihat demirhan tahliyesine karar verdi <iend>']"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xa9pP7wrr_j"
      },
      "source": [
        "text = TextCleaner(\"\"\"Bursa'nın Yıldırım ilçesinde bir vatandaş, sokağa çıkma kısıtlamasını ihlal ederek, şehir içi yolcu taşımacılığında kullanılan minibüste yolculuk etti. Polis ekiplerine \"İzin belgem yok ama 'WhatsApp' grubumuz var, olmaz mı? Ben de minibüsçüyüm\" diyen şahsa 3 bin 150 TL ceza yazıldı.\n",
        "Bursa İl Emniyet Müdürlüğü ekipleri, sokağa çıkma kısıtlaması nedeniyle kent genelinde uygulama noktaları oluşturdu. Yıldırım'ın Otosansit Kavşağı'ndaki kontrol noktasında şehir içi yolcu taşımacılığı yapılan otobüs ve minibüsleri denetleyen ekipler, yolcuların izin belgelerini inceledi.\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWZUVsfVCS2I",
        "outputId": "2f20c97f-0533-4c0d-a511-87a546b83545"
      },
      "source": [
        "generate(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Girdi:\n",
            "bursa yıldırım ilçesinde vatandaş sokağa çıkma kısıtlamasını ihlal şehir içi yolcu taşımacılığında kullanılan minibüste yolculuk etti polis ekiplerine i̇zin belgem yok whatsapp grubumuz olmaz minibüsçüyüm diyen şahsa 3 bin 150 tl ceza yazıldı bursa i̇l emniyet müdürlüğü ekipleri sokağa çıkma kısıtlaması nedeniyle kent genelinde uygulama noktaları oluşturdu yıldırım ın otosansit kavşağı ndaki kontrol noktasında şehir içi yolcu taşımacılığı yapılan otobüs minibüsleri denetleyen ekipler yolcuların izin belgelerini inceledi\n",
            "\n",
            "Üretililen Başlık:\n",
            "  asker diye fırsat telefonu bulunan şüpheli yemek yakalandı <stop>\n",
            "\n",
            "Gerçek Başlık:\n",
            "None\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}